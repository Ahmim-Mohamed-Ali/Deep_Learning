{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0cebeb-3b58-4147-b529-3acbc3bb453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b49e74-147c-4d90-affc-cc6f47103860",
   "metadata": {},
   "source": [
    "2. Define the model:\n",
    "Create a simple neural network model with a Flatten layer followed by two Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44da6b78-d067-4078-9673-fee943256c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Model\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4c9bc-41c1-4c56-93cf-48c3d6477ffd",
   "metadata": {},
   "source": [
    "3. Define Loss Function and Optimizer:\n",
    "Use Sparse Categorical Crossentropy for the loss function.\n",
    "Use the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc9cf48-8469-4cfa-bbfa-3c8402d57512",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimize=tf.keras.optimizers.Adam()\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af045c70-7c23-4010-8560-820a4793fe72",
   "metadata": {},
   "source": [
    "## 4. Implement the Custom Training Loop:\n",
    "Iterate over the dataset for a specified number of epochs.\n",
    "Compute the loss and apply gradients to update the model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ba394f-6a20-40dc-8b06-9a42f155fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 0.04315980523824692  Accuracy = 1.0 \n",
      "Epoch 1 Step 200: Loss = 0.07757634669542313  Accuracy = 0.9751243591308594 \n",
      "Epoch 1 Step 400: Loss = 0.05379654839634895  Accuracy = 0.9724127054214478 \n",
      "Epoch 1 Step 600: Loss = 0.032775189727544785  Accuracy = 0.9737936854362488 \n",
      "Epoch 1 Step 800: Loss = 0.04144629091024399  Accuracy = 0.9739778637886047 \n",
      "Epoch 1 Step 1000: Loss = 0.17775724828243256  Accuracy = 0.9746191501617432 \n",
      "Epoch 1 Step 1200: Loss = 0.07076407968997955  Accuracy = 0.9746565222740173 \n",
      "Epoch 1 Step 1400: Loss = 0.10073287785053253  Accuracy = 0.9748393893241882 \n",
      "Epoch 1 Step 1600: Loss = 0.10931351035833359  Accuracy = 0.9745861887931824 \n",
      "Epoch 1 Step 1800: Loss = 0.04842286556959152  Accuracy = 0.9750832915306091 \n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.015033794566988945  Accuracy = 0.9754464030265808 \n",
      "Epoch 2 Step 200: Loss = 0.07736096531152725  Accuracy = 0.9761560559272766 \n",
      "Epoch 2 Step 400: Loss = 0.044564854353666306  Accuracy = 0.9767135381698608 \n",
      "Epoch 2 Step 600: Loss = 0.035450875759124756  Accuracy = 0.9774459600448608 \n",
      "Epoch 2 Step 800: Loss = 0.028371531516313553  Accuracy = 0.9778237342834473 \n",
      "Epoch 2 Step 1000: Loss = 0.1288078874349594  Accuracy = 0.9782249927520752 \n",
      "Epoch 2 Step 1200: Loss = 0.05841436609625816  Accuracy = 0.9785029292106628 \n",
      "Epoch 2 Step 1400: Loss = 0.06474457681179047  Accuracy = 0.9787564873695374 \n",
      "Epoch 2 Step 1600: Loss = 0.060346972197294235  Accuracy = 0.9788999557495117 \n",
      "Epoch 2 Step 1800: Loss = 0.026713700965046883  Accuracy = 0.9792148470878601 \n"
     ]
    }
   ],
   "source": [
    "# Step 4: Implement the Custom Training Loop\n",
    "\n",
    "epochs = 2\n",
    "# train_dataset = train_dataset.repeat(epochs)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)  # Forward pass\n",
    "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimize.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "        # Logging the loss every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}  Accuracy = {accuracy_metric.result().numpy()} ')\n",
    "# Reset the metric at the end of each epoch\n",
    "accuracy_metric.reset_state()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179ca52-6967-481a-94d8-fcf94a46fd1b",
   "metadata": {},
   "source": [
    "### Custom Callback for Advanced Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1855c69a-460b-4f43-b379-208ef19ceefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Step 4: Implement the Custom Callback \n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f'End of epoch {epoch + 1}, loss: {logs.get(\"loss\")}, accuracy: {logs.get(\"accuracy\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d9920e-d4d0-459f-a8cf-83824102e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 0.014878474175930023 Accuracy = 1.0\n",
      "Epoch 1 Step 200: Loss = 0.06551411747932434 Accuracy = 0.9872512221336365\n",
      "Epoch 1 Step 400: Loss = 0.031689975410699844 Accuracy = 0.9865959882736206\n",
      "Epoch 1 Step 600: Loss = 0.03019825741648674 Accuracy = 0.986896812915802\n",
      "Epoch 1 Step 800: Loss = 0.016490695998072624 Accuracy = 0.9868913888931274\n",
      "Epoch 1 Step 1000: Loss = 0.08944132924079895 Accuracy = 0.9874188303947449\n",
      "Epoch 1 Step 1200: Loss = 0.036088816821575165 Accuracy = 0.9875364303588867\n",
      "Epoch 1 Step 1400: Loss = 0.04080403968691826 Accuracy = 0.9874197244644165\n",
      "Epoch 1 Step 1600: Loss = 0.05401533097028732 Accuracy = 0.9873126149177551\n",
      "Epoch 1 Step 1800: Loss = 0.023965956643223763 Accuracy = 0.9875763654708862\n",
      "End of epoch 1, loss: 0.028269894421100616, accuracy: 0.9877166748046875\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.00859090220183134 Accuracy = 1.0\n",
      "Epoch 2 Step 200: Loss = 0.03307466208934784 Accuracy = 0.9902052283287048\n",
      "Epoch 2 Step 400: Loss = 0.03815466910600662 Accuracy = 0.9905704259872437\n",
      "Epoch 2 Step 600: Loss = 0.02635955438017845 Accuracy = 0.9912645816802979\n",
      "Epoch 2 Step 800: Loss = 0.012409760616719723 Accuracy = 0.9907927513122559\n",
      "Epoch 2 Step 1000: Loss = 0.06250426173210144 Accuracy = 0.9908216595649719\n",
      "Epoch 2 Step 1200: Loss = 0.016705460846424103 Accuracy = 0.9909190535545349\n",
      "Epoch 2 Step 1400: Loss = 0.011779164895415306 Accuracy = 0.9907878041267395\n",
      "Epoch 2 Step 1600: Loss = 0.04124772176146507 Accuracy = 0.9906893968582153\n",
      "Epoch 2 Step 1800: Loss = 0.00893553625792265 Accuracy = 0.9908905029296875\n",
      "End of epoch 2, loss: 0.006830794271081686, accuracy: 0.9910500049591064\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Implement the Custom Training Loop with Custom Callback\n",
    "\n",
    "epochs = 2\n",
    "custom_callback = CustomCallback()  # Initialize the custom callback\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimize.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Call the custom callback at the end of each epoch\n",
    "    custom_callback.on_epoch_end(epoch, logs={'loss': loss_value.numpy(), 'accuracy': accuracy_metric.result().numpy()})\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()  # Use reset_state() instead of reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8bcb5-1107-4d33-bc60-004471fcd28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
