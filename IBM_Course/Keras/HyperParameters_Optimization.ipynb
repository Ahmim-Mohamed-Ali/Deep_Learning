{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d516b573-f616-4581-8201-933ba852e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import necessary libraries\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all logs, 1 = filter out INFO, 2 = filter out INFO and WARNING, 3 = ERROR only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba5633-30d4-4a26-8336-2c5dc01777da",
   "metadata": {},
   "source": [
    "Explanation\n",
    "This code imports the necessary libraries:\n",
    "\n",
    "- keras_tuner: Used for hyperparameter tuning.\n",
    "- Sequential: A linear stack of layers in Keras.\n",
    "- Dense, Flatten: Common Keras layers.\n",
    "- mnist: The MNIST dataset, a standard dataset for image classification.\n",
    "- Adam: An optimizer in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074d5c5a-0033-4aa5-85c8-cb0a22c239fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Validation data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
    "x_train, x_val = x_train / 255.0, x_val / 255.0\n",
    "\n",
    "print(f'Training data shape: {x_train.shape}')\n",
    "print(f'Validation data shape: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d450831-de2f-4649-b979-3827101e4708",
   "metadata": {},
   "source": [
    "### Exercise 2: Defining the model with hyperparameters\n",
    "In this exercise, you define a model-building function that uses the HyperParameters object to specify the number of units in a dense layer and the learning rate. This function returns a compiled Keras model that is ready for hyperparameter tuning.\n",
    "\n",
    "Define a model-building function:\n",
    "\n",
    "- Create a function build_model that takes a HyperParameters object as input.\n",
    "- Use the HyperParameters object to define the number of units in a dense layer and the learning rate for the optimizer.\n",
    "- Compile the model with sparse categorical cross-entropy loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa03e62-fbbb-4c52-8114-0839fc1f1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model-building function \n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f077a-91d3-437d-a695-ca3106d2df00",
   "metadata": {},
   "source": [
    "### Exercise 3: Configuring the hyperparameter search\n",
    "This exercise guides you through configuring Keras Tuner. You create a RandomSearch tuner, specifying the model-building function, the optimization objective, the number of trials, and the directory for storing results. The search space summary provides an overview of the hyperparameters being tuned.\n",
    "\n",
    "Create a RandomSearch Tuner:\n",
    "\n",
    "- Use the RandomSearch class from Keras Tuner.\n",
    "- Specify the model-building function, optimization objective (validation accuracy), number of trials, and directory for storing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c777d0-1a7c-4b75-af90-d541cc0eb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "# Create a RandomSearch Tuner \n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Display a summary of the search space \n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9f5af-d9b8-442f-b3df-2d83d50f49ce",
   "metadata": {},
   "source": [
    "Explanation\n",
    "This code sets up a Keras Tuner RandomSearch:\n",
    "\n",
    "- build_model: The model-building function.\n",
    "- objective='val_accuracy': The metric to optimize (validation accuracy).\n",
    "- max_trials=10: The maximum number of different hyperparameter configurations to try.\n",
    "- executions_per_trial=2: The number of times to run each configuration.\n",
    "- directory='my_dir': Directory to save the results.\n",
    "- project_name='intro_to_kt': Name of the project for organizing results.\n",
    "Displays a summary of the hyperparameter search space, providing an overview of the hyperparameters being tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cd2b6-b2b1-4b7a-bd27-c59481bf49af",
   "metadata": {},
   "source": [
    "### Exercise 4: Running the hyperparameter search\n",
    "In this exercise, you run the hyperparameter search using the search method of the tuner. You provide the training and validation data along with the number of epochs. After the search is complete, the results summary displays the best hyperparameter configurations found.\n",
    "\n",
    "Run the search:\n",
    "\n",
    "- Use the search method of the tuner.\n",
    "- Pass in the training data, validation data, and the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab064d0-56e0-490d-8d5e-883fb922b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 50s]\n",
      "val_accuracy: 0.9796499907970428\n",
      "\n",
      "Best val_accuracy So Far: 0.9808500111103058\n",
      "Total elapsed time: 00h 16m 26s\n",
      "Results summary\n",
      "Results in my_dir\\intro_to_kt\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.0013263444829043885\n",
      "Score: 0.9808500111103058\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 416\n",
      "learning_rate: 0.0025214364578715043\n",
      "Score: 0.9796499907970428\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.001561164109127508\n",
      "Score: 0.9781999886035919\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0012564412521369585\n",
      "Score: 0.9772499799728394\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0005162885734768005\n",
      "Score: 0.976500004529953\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0007950738895236766\n",
      "Score: 0.976500004529953\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 224\n",
      "learning_rate: 0.00220845836973479\n",
      "Score: 0.9758999943733215\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 352\n",
      "learning_rate: 0.00328444446297855\n",
      "Score: 0.9738499820232391\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.00019937773888529741\n",
      "Score: 0.9718500077724457\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 480\n",
      "learning_rate: 0.005513981671139741\n",
      "Score: 0.9702499806880951\n"
     ]
    }
   ],
   "source": [
    "# Run the hyperparameter search \n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val)) \n",
    "\n",
    "# Display a summary of the results \n",
    "tuner.results_summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a3351-0d3e-41aa-9632-6e79b3a543b2",
   "metadata": {},
   "source": [
    "### Exercise 5: Analyzing and using the best hyperparameters\n",
    "In this exercise, you retrieve the best hyperparameters found during the search and print their values. You then build a model with these optimized hyperparameters and train it on the full training data set. Finally, you evaluate the modelâ€™s performance on the test set to ensure that it performs well with the selected hyperparameters.\n",
    "\n",
    "Retrieve the best hyperparameters:\n",
    "\n",
    "- Use the get_best_hyperparameters method to get the best hyperparameters.\n",
    "- Print the optimal values for the hyperparameters.\n",
    "Build and train the model:\n",
    "\n",
    "- Build a model using the best hyperparameters.\n",
    "- Train the model on the full training data set and evaluate its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018f230-b3b0-474f-bd67-f10839cdee7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
